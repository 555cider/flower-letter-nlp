{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>문정희</td>\n",
       "      <td>가을 노트</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt;&lt;br&gt;그대 떠나간 후&lt;br&gt;나의 가을은&lt;br&gt;조금만 건드려도&lt;br&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이순</td>\n",
       "      <td>가을비 오는 날은</td>\n",
       "      <td>&lt;br&gt;자정이 되어 간신히 그치는 비&lt;br&gt;간신히 버리는 그리움&lt;br&gt;그동안 너무 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이성선</td>\n",
       "      <td>가을 편지</td>\n",
       "      <td>&lt;br&gt;잎이 떨어지고 있습니다&lt;br&gt;원고지처럼 하늘이 한 칸씩&lt;br&gt;비어 가고 있습...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>박제영</td>\n",
       "      <td>가을에는</td>\n",
       "      <td>&lt;br&gt;가을에는 잠시 여행을 떠날 일이다&lt;br&gt;그리 수선스러운 준비는 하지 말고&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최영미</td>\n",
       "      <td>가을에는</td>\n",
       "      <td>&lt;br&gt;내가 그를 사랑한 것도 아닌데&lt;br&gt;미칠 듯 그리워질 때가 있다&lt;br&gt;바람의...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author      title                                            content\n",
       "0    문정희      가을 노트  <br><br><br>그대 떠나간 후<br>나의 가을은<br>조금만 건드려도<br>...\n",
       "1     이순  가을비 오는 날은  <br>자정이 되어 간신히 그치는 비<br>간신히 버리는 그리움<br>그동안 너무 ...\n",
       "2    이성선      가을 편지  <br>잎이 떨어지고 있습니다<br>원고지처럼 하늘이 한 칸씩<br>비어 가고 있습...\n",
       "3    박제영       가을에는  <br>가을에는 잠시 여행을 떠날 일이다<br>그리 수선스러운 준비는 하지 말고<b...\n",
       "4    최영미       가을에는  <br>내가 그를 사랑한 것도 아닌데<br>미칠 듯 그리워질 때가 있다<br>바람의..."
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('nlp_poem.csv')\n",
    "poem = data\n",
    "\n",
    "poem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리, 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = [\n",
    "#     '입니다', '합니다', '않아요', '않으리', '하여', '하니', '있듯', '아니라', '아니고', '되어야만',\n",
    "#     '되지요', '해야', '한다', '하리' '하는', '하지', '있습니다', '아니다', '든다', '하게', '있다', '있다는',\n",
    "#     '했다는', '있지는', '그게', '했다', '했던', '되어', '그것',\n",
    "#     '당신', '해요', '무엇', '내게', '내게는', '않습니다', '했으먄', '있기에', '하는', '바로', '나를', '갖지',\n",
    "#     '가는', '더욱', '있을', '느냐구요', '있으먄', '있기만', '들을', '하니까', '하면', '하기에', '무엇', '되시건', '돼요',\n",
    "#     '그대', '있어', '주므로', '이오', '주려', '건가', '모든', '있으니', '왔습니다', '것임', '있으며', '하노라고',\n",
    "#     '하죠', '주길', '였어요', '였답니다', '원했지요', '같은', '보아',\n",
    "#     '했습니다', '있는', '나도', '맡는다', '로써', '보여도', '여겼던', '보죠', '때문', '싫기', '하길', '하세요', '래야',\n",
    "#     '행여', '아는', '마는', '다른', '없는', '하는것은', '이릅니다', '있어', '없는', '없는가', '한다면', '않는다면',\n",
    "#     '않기', '대신', '하기', '됩니다', '하고자', '있는', '있건', '하소', '않게', '다음',\n",
    "#     '시오', '이겠지요', '알아야', '위해', '하다면', '이기만', '하신다면', '해주리라', '없을지도', '있겠지만', '해서만',\n",
    "#     '주세요', '마세요', '오직', '가장', '냅니다', '했었다고','되었나', '아닙니다', '진다는', '않으니', '마세요',\n",
    "#     '없다', '머는', '있으면', '봅니다', '아니래', '하는게', '아닌데', '있었습니다',\n",
    "    \n",
    "    \n",
    "#     '있다면', '아름다운', '그대', '사람', '내게', '싶습니다', '않는', '싶다', '사랑', '우리', '하나',\n",
    "#     '되고', '가고', '좋은', '된다', '만나고', '그런',\n",
    "#     '싶은', '사는', '않은',\n",
    "#     '작은', '많은', '있었다',\n",
    "#     '생각', '마음', '슬픔',\n",
    "#     '친구'\n",
    "# ]\n",
    "\n",
    "\n",
    "stopwords = [\n",
    "    '하다', '있다', '것', '내', '나', '그', '않다', '수', '없다', '싶다', '이다',\n",
    "    '되다', '날', '말', '이', '더', '때문', '그렇다', '알', '위', '곳', '일', '저', '네', '못', '줄' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    from konlpy.tag import Okt\n",
    "    tagger = Okt()\n",
    "    \n",
    "    text = text.replace(\"<br>\", \" \")\n",
    "    okt_pos = tagger.pos(text, norm=True, stem=True)\n",
    "    pure_words = [word for word, hts in okt_pos if hts in ['Adjective', 'Adverb','Alpha', 'Eomi', 'Exclamation', 'Noun', 'Suffix' ,'Verb' ]]\n",
    "    \n",
    "    return pure_words\n",
    "\n",
    "def nonemeaning(text):\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 시 내용 가져오기\n",
    "contents = poem['content']\n",
    "contents = contents.apply(tokenize)\n",
    "# contents = contents.apply(nonemeaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [그대, 떠나가다, 후, 나, 가을, 조금, 건드리다, 우수수, 몸, 떨다, 못, ...\n",
       "1    [자정, 되어다, 간신히, 그치다, 비, 간신히, 버리다, 그리움, 그동안, 너무,...\n",
       "2    [잎, 떨어지다, 있다, 원고지, 하늘, 하다, 칸, 씩, 비어, 가다, 있다, 그...\n",
       "3    [가을, 잠시, 여행, 떠나다, 일이, 그리다, 수선스럽다, 준비, 하다, 그리다,...\n",
       "4    [내, 그, 사랑, 것, 아니다, 미치다, 듯, 그립다, 때, 있다, 바람, 손, ...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 초기화 및 모델 학습\n",
    "# from gensim.models import word2vec\n",
    "\n",
    "# # 모델 학습\n",
    "# model = word2vec.Word2Vec(contents, min_count=1)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 단어 사전 수\n",
    "# len(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 단어 사전에서 상위 10개만 보기\n",
    "# vocab = list(model.wv.key_to_index.keys())\n",
    "# vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Counter로 자주 등장하는 단어 보기\n",
    "# from collections import Counter\n",
    "# dict(Counter(vocab).most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv['가을']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.most_similar('사랑')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.wv.similarity('가을', '가게')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 외부 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "WORD2VEC_PATH = 'D:/New folder/ko/ko.bin'\n",
    "\n",
    "ko_model = gensim.models.Word2Vec.load(WORD2VEC_PATH)\n",
    "ko_model.wv.save_word2vec_format(\"ko.bin.gz\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2044\n"
     ]
    }
   ],
   "source": [
    "my_model = Word2Vec(size=330, min_count=1, window=10, iter=35) #(size=330, min_count=1, window=10, iter=35)\n",
    "my_model.build_vocab(contents)\n",
    "examples = my_model.corpus_count\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.build_vocab([list(model.wv.vocab.keys())], update=True)\n",
    "word2vec_model.intersect_word2vec_format(\"ko.bin.gz\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808332, 6874945)"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.train(contents, total_examples=examples, epochs=my_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17860278"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.wv.similarity('가을비', '우정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('쓰다', 0.6921025514602661),\n",
       " ('부치다', 0.6585524678230286),\n",
       " ('보내다', 0.6547990441322327),\n",
       " ('말쑥하다', 0.5989377498626709),\n",
       " ('옵니다', 0.597987949848175),\n",
       " ('아리랑', 0.5639522075653076),\n",
       " ('귀절', 0.5604039430618286),\n",
       " ('우표', 0.5602738261222839),\n",
       " ('겉봉', 0.5428212881088257),\n",
       " ('마분지', 0.5377181768417358)]"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.wv.most_similar('편지')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평균 벡터 추천 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectors(document_list):\n",
    "#     document_embedding_list = []\n",
    "\n",
    "#     # 각 문서에 대해서\n",
    "#     for line in document_list:\n",
    "#         doc2vec = None\n",
    "#         count = 0\n",
    "#         for word in line.split():\n",
    "#             if word in word2vec_model.wv.vocab:\n",
    "#                 count += 1\n",
    "#                 # 해당 문서에 있는 모든 단어들의 벡터값을 더한다.\n",
    "#                 if doc2vec is None:\n",
    "#                     doc2vec = word2vec_model[word]\n",
    "#                 else:\n",
    "#                     doc2vec = doc2vec + word2vec_model[word]\n",
    "\n",
    "#         if doc2vec is not None:\n",
    "#             # 단어 벡터를 모두 더한 벡터의 값을 문서 길이로 나눠준다.\n",
    "#             doc2vec = doc2vec / count\n",
    "#             document_embedding_list.append(doc2vec)\n",
    "#         else:\n",
    "#             document_embedding_list.append(0)\n",
    "\n",
    "#     # 각 문서에 대한 문서 벡터 리스트를 리턴\n",
    "#     return document_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_embedding_list = vectors(poem['content'])\n",
    "# print('문서 개수 :', len(poem['content']))\n",
    "# print('문서 벡터의 수 :',len(document_embedding_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cosine_similarities = cosine_similarity(document_embedding_list, document_embedding_list)\n",
    "# print('코사인 유사도 매트릭스의 크기 :',cosine_similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_similarities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommendations(num):\n",
    "#     data = pd.read_csv('nlp_poem.csv')\n",
    "#     poem = data['content']\n",
    "\n",
    "#     # 입력된 책과 줄거리(document embedding)가 유사한 책 5개 선정.\n",
    "#     sim_scores = list(enumerate(cosine_similarities[num]))\n",
    "#     sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "#     sim_scores = sim_scores[1:6]\n",
    "\n",
    "#     # 가장 유사한 책 5권의 인덱스\n",
    "#     poem_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "#     # 전체 데이터프레임에서 해당 인덱스의 행만 추출. 5개의 행을 가진다.\n",
    "#     recommend = poem.iloc[poem_indices].reset_index(drop=True)\n",
    "\n",
    "#     print(list(recommend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 500\n",
    "\n",
    "# print(poem['content'][num])\n",
    "# recommendations(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
